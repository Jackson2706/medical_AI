{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. Define utils of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_comparison(a, b):\n",
    "    \"\"\"\n",
    "    This function compares two values a and b.\n",
    "    If they are equal, it returns 1.\n",
    "    If they are not equal, it returns 0.\n",
    "    \"\"\"\n",
    "    if a == b:\n",
    "        # If a is equal to b, return 1\n",
    "        return 1\n",
    "    else:\n",
    "        # If a is not equal to b, return 0\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def gram_matrix(list_of_score):\n",
    "    \"\"\"\n",
    "    This function computes the Gram matrix for a list of scores.\n",
    "    \n",
    "    The Gram matrix is a matrix of pairwise comparisons of scores.\n",
    "    Each element [i][j] in the matrix represents the result of\n",
    "    comparing list_of_score[i] with list_of_score[j] using the\n",
    "    pair_comparison function.\n",
    "    \n",
    "    Args:\n",
    "    - list_of_score: A list of scores\n",
    "    \n",
    "    Returns:\n",
    "    - gram_matrix: The Gram matrix computed from the pairwise comparisons\n",
    "    \"\"\"\n",
    "    # Get the length of the list of scores\n",
    "    n = len(list_of_score)\n",
    "    \n",
    "    # Initialize the Gram matrix with zeros\n",
    "    gram_matrix = [[0 for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # Iterate through each pair of scores\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # Compute the pairwise comparison using the pair_comparison function\n",
    "            gram_matrix[i][j] = pair_comparison(list_of_score[i], list_of_score[j])\n",
    "    \n",
    "    # Return the computed Gram matrix\n",
    "    return gram_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "list_of_score = [1,2,3,2,3,4,2,1,4]\n",
    "gram_matrix(list_of_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_randomly(data, labels, k):\n",
    "    \"\"\"\n",
    "    Split the data and labels randomly into groups of size k.\n",
    "\n",
    "    Args:\n",
    "    - data: List of data elements\n",
    "    - labels: List of corresponding labels\n",
    "    - k: Size of each group\n",
    "\n",
    "    Returns:\n",
    "    - image_groups: List of groups containing data elements\n",
    "    - label_groups: List of groups containing corresponding labels\n",
    "    \"\"\"\n",
    "    # Shuffle data and labels in sync\n",
    "    combined_data = list(zip(data, labels))\n",
    "    random.shuffle(combined_data)\n",
    "    # Split the shuffled data into groups of size k\n",
    "    num_groups = len(combined_data) // k\n",
    "    image_groups = [data[i * k : (i + 1) * k] for i in range(num_groups)]\n",
    "    label_groups = [labels[i * k : (i + 1) * k] for i in range(num_groups)]\n",
    "    return image_groups, label_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/envs/Paper/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "\n",
    "from torchvision import transforms\n",
    "from typing import Tuple\n",
    "class SeveritySimilarityDataset(Dataset):\n",
    "    def __init__(self, annotation_file_path: str, dataset_dir: str, phase: str = \"training\", num_per_cluster: int = 5, input_size: Tuple[int] = (224, 224)) -> None:\n",
    "        \"\"\"\n",
    "        Dataset class for severity similarity task.\n",
    "\n",
    "        Args:\n",
    "        - annotation_df: DataFrame containing annotations\n",
    "        - dataset_dir: Directory containing image data\n",
    "        - phase: Phase of the dataset (e.g., \"training\", \"validation\", \"testing\")\n",
    "        - num_per_cluster: Number of images per cluster\n",
    "        \"\"\"\n",
    "        super(SeveritySimilarityDataset, self).__init__()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        annotation_df = pd.read_csv(annotation_file_path)\n",
    "        # Filter data based on the specified phase\n",
    "        data = annotation_df[annotation_df[\"split\"] == phase]\n",
    "        # Concatenate study_id and image_id to get image paths\n",
    "        image_paths_df = data[\"study_id\"] + \"/\" + data[\"image_id\"] +\".dicom\"\n",
    "        image_paths = image_paths_df.tolist()\n",
    "    \n",
    "        # Get labels\n",
    "        labels_df = data[\"breast_birads\"]\n",
    "        labels = labels_df.to_list()\n",
    "\n",
    "        # Split data into clusters\n",
    "        self.image_cluster_list, self.label_cluster_list = split_data_randomly(image_paths, labels, num_per_cluster)\n",
    "\n",
    "\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of clusters in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.label_cluster_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Retrieves a cluster of images and its corresponding label cluster.\n",
    "\n",
    "        Args:\n",
    "        - index: Index of the cluster to retrieve\n",
    "\n",
    "        Returns:\n",
    "        - images: List of images in the cluster\n",
    "        - gram_matrix: Gram matrix computed from the label cluster\n",
    "        \"\"\"\n",
    "        image_cluster = self.image_cluster_list[index]\n",
    "        label_cluster = self.label_cluster_list[index]\n",
    "        images = []\n",
    "        for image_path in image_cluster:\n",
    "            abs_image_path = os.path.join(self.dataset_dir, image_path)\n",
    "            # Read and preprocess image\n",
    "            image =  self._read_resize_dicom(os.path.join(self.dataset_dir,image_path), self.input_size) # Transpose image tensor\n",
    "            images.append(image)\n",
    "        # # Compute Gram matrix\n",
    "        gram_matrix_ = gram_matrix(label_cluster)\n",
    "        return  images, torch.tensor(gram_matrix_).to(torch.float)\n",
    "    \n",
    "    def _read_resize_dicom(self, filepath, new_size):\n",
    "         # Đọc file DICOM\n",
    "        dicom_data = pydicom.dcmread(filepath)\n",
    "        \n",
    "        # Chuyển đổi dữ liệu DICOM thành mảng numpy\n",
    "        image_array = dicom_data.pixel_array\n",
    "        \n",
    "        # Chuyển đổi mảng numpy thành ảnh PIL\n",
    "        image_pil = Image.fromarray(image_array)\n",
    "        \n",
    "        # Kiểm tra chế độ của ảnh\n",
    "        if image_pil.mode != 'L':\n",
    "            image_pil = image_pil.convert('L')  # Chuyển đổi sang chế độ 'L' (grayscale) nếu cần thiết\n",
    "        \n",
    "        # Tạo ảnh RGB từ ảnh đơn kênh bằng cách sao chép giá trị của kênh đó vào cả ba kênh\n",
    "        image_pil = Image.merge('RGB', (image_pil, image_pil, image_pil))\n",
    "        \n",
    "        # Resize ảnh\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(new_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        resized_image = transform(image_pil)\n",
    "        resized_image = resized_image.to(torch.float)\n",
    "        \n",
    "        return resized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "tensor([[1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [1., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "data = SeveritySimilarityDataset(\"data.csv\", \"data\", \"training\", 6)\n",
    "print(len(data))\n",
    "print(data[3][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "\n",
    "class Setting_2_model(nn.Module):\n",
    "    def __init__(self, model_name: str, embed_dim: int):\n",
    "        \"\"\"\n",
    "        A custom model for Setting 2, which uses different pre-trained models\n",
    "        based on the specified `model_name`.\n",
    "\n",
    "        Args:\n",
    "        - model_name: Name of the pre-trained model to be used\n",
    "        - embed_dim: Dimension of the output embeddings\n",
    "        \"\"\"\n",
    "        super(Setting_2_model, self).__init__()\n",
    "\n",
    "        # Load the specified pre-trained model\n",
    "        if model_name.startswith('resnet'):\n",
    "            if model_name == 'resnet50':\n",
    "                self.model = models.resnet50(pretrained=True)\n",
    "            elif model_name == 'resnet101':\n",
    "                self.model = models.resnet101(pretrained=True)\n",
    "            elif model_name == 'resnet152':\n",
    "                self.model = models.resnet152(pretrained=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported ResNet model: {model_name}\")\n",
    "                \n",
    "            num_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        elif model_name.startswith('densenet'):\n",
    "            if model_name == 'densenet121':\n",
    "                self.model = models.densenet121(pretrained=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported DenseNet model: {model_name}\")\n",
    "                \n",
    "            num_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        elif model_name.startswith('vit'):\n",
    "            self.model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "            num_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "        - images: A list of input images\n",
    "\n",
    "        Returns:\n",
    "        - gram_matrix: The Gram matrix computed from the embeddings\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        # Iterate over the list of input images\n",
    "        for image in images:\n",
    "            # Pass the image through the pre-trained model\n",
    "            image_embedding = self.model(image)\n",
    "            # Append the embedding to the list\n",
    "            embeddings.append(image_embedding)\n",
    "        # Stack the embeddings along a new dimension\n",
    "        embeddings_tensor = torch.stack(embeddings, dim=1)\n",
    "        # Normalize the embeddings\n",
    "        embeddings_normalized = torch.nn.functional.normalize(embeddings_tensor, p=2, dim=2)\n",
    "\n",
    "        # Compute the Gram matrix\n",
    "        gram_matrix = torch.matmul(embeddings_normalized, embeddings_normalized.transpose(1, 2))\n",
    "        return gram_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        \"\"\"\n",
    "        Contrastive Loss function for computing the loss between predicted\n",
    "        and ground truth Gram matrices.\n",
    "\n",
    "        Args:\n",
    "        - margin: Margin value for the loss calculation\n",
    "        \"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, gram_matrix_predicted, gram_matrix_ground_truth):\n",
    "        \"\"\"\n",
    "        Forward pass of the Contrastive Loss function.\n",
    "\n",
    "        Args:\n",
    "        - gram_matrix_predicted: Predicted Gram matrix\n",
    "        - gram_matrix_ground_truth: Ground truth Gram matrix\n",
    "\n",
    "        Returns:\n",
    "        - loss: Contrastive Learning Loss\n",
    "        \"\"\"\n",
    "        loss = torch.mean(gram_matrix_ground_truth) * pow(gram_matrix_predicted, 2) + (1-gram_matrix_ground_truth) * pow(torch.clamp(self.margin - gram_matrix_predicted, min=0.0), 2)\n",
    "        return torch.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7467)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import torch\n",
    "\n",
    "gt = [1,2,3,2,3,4,2,1,4]\n",
    "gt = torch.tensor(gram_matrix(gt),dtype=torch.float)\n",
    "\n",
    "pred = [1,2,3,2,3,4,2,2,4]\n",
    "pred = torch.tensor(gram_matrix(pred), dtype=torch.float)\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "loss = criterion(pred, gt)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs=10, batch_size=32, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train the model using the provided datasets.\n",
    "\n",
    "    Args:\n",
    "    - model: The model to be trained\n",
    "    - train_dataset: Dataset for training\n",
    "    - val_dataset: Dataset for validation\n",
    "    - num_epochs: Number of epochs for training\n",
    "    - batch_size: Batch size for training\n",
    "    - learning_rate: Learning rate for optimization\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained model\n",
    "    - train_losses: List of training losses\n",
    "    - val_losses: List of validation losses\n",
    "    \"\"\"\n",
    "    # Define data loaders for training and validation\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Lists to store training and validation losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    print(\"Training started...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader, 1):\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Compute average training loss for the epoch\n",
    "        epoch_train_loss = running_train_loss / len(train_dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(val_loader, 1):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                if i % 1 == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Batch [{i}/{len(val_loader)}], Val Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Compute average validation loss for the epoch\n",
    "        epoch_val_loss = running_val_loss / len(val_dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "\n",
    "def test_model(model, test_dataset, batch_size=32):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "    - model: The trained model to be evaluated\n",
    "    - test_dataset: Dataset for testing\n",
    "    - batch_size: Batch size for testing\n",
    "\n",
    "    Returns:\n",
    "    - test_loss: Test loss\n",
    "    \"\"\"\n",
    "    # Define data loader for testing\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables for computing test loss\n",
    "    running_test_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    print(\"Testing started...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_test_loss += loss.item() * images.size(0)\n",
    "            num_samples += images.size(0)\n",
    "\n",
    "    # Compute test loss\n",
    "    test_loss = running_test_loss / num_samples\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(\"Testing completed.\")\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "# Example usage:\n",
    "# model = Setting_2_model(model_name='resnet50', embed_dim=512)\n",
    "# train_dataset = SeveritySimilarityDataset(train_annotation_df, dataset_dir, phase='training')\n",
    "# val_dataset = SeveritySimilarityDataset(val_annotation_df, dataset_dir, phase='validation')\n",
    "# test_dataset = SeveritySimilarityDataset(test_annotation_df, dataset_dir, phase='testing')\n",
    "# trained_model, train_losses, val_losses = train_model(model, train_dataset, val_dataset, num_epochs=10, batch_size=32, learning_rate=0.001)\n",
    "# test_loss = test_model(trained_model, test_dataset, batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"annotation_data_path\": \"data.csv\",\n",
    "    \"image_folder_path\": \"data\",\n",
    "    \"model_encoder\": \"resnet50\",\n",
    "    \"embedding_dim\": 512, \n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"num_epoch\": 20,\n",
    "    \"batch_size\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/envs/Paper/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/envs/Paper/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n",
      "Epoch [1/20], Batch [1/18], Train Loss: 0.5619\n",
      "Epoch [1/20], Batch [2/18], Train Loss: 0.4393\n",
      "Epoch [1/20], Batch [3/18], Train Loss: 0.5901\n",
      "Epoch [1/20], Batch [4/18], Train Loss: 0.4858\n",
      "Epoch [1/20], Batch [5/18], Train Loss: 0.3584\n",
      "Epoch [1/20], Batch [6/18], Train Loss: 0.3692\n",
      "Epoch [1/20], Batch [7/18], Train Loss: 0.6961\n",
      "Epoch [1/20], Batch [8/18], Train Loss: 0.3447\n",
      "Epoch [1/20], Batch [9/18], Train Loss: 0.3871\n",
      "Epoch [1/20], Batch [10/18], Train Loss: 0.8018\n",
      "Epoch [1/20], Batch [11/18], Train Loss: 0.6627\n",
      "Epoch [1/20], Batch [12/18], Train Loss: 0.7648\n",
      "Epoch [1/20], Batch [13/18], Train Loss: 0.6518\n",
      "Epoch [1/20], Batch [14/18], Train Loss: 0.6849\n",
      "Epoch [1/20], Batch [15/18], Train Loss: 0.6548\n",
      "Epoch [1/20], Batch [16/18], Train Loss: 0.4350\n",
      "Epoch [1/20], Batch [17/18], Train Loss: 0.6974\n",
      "Epoch [1/20], Batch [18/18], Train Loss: 0.3782\n",
      "Epoch [1/20], Validation Batch [1/5], Val Loss: 0.5107\n",
      "Epoch [1/20], Validation Batch [2/5], Val Loss: 0.4040\n",
      "Epoch [1/20], Validation Batch [3/5], Val Loss: 0.3791\n",
      "Epoch [1/20], Validation Batch [4/5], Val Loss: 0.5115\n",
      "Epoch [1/20], Validation Batch [5/5], Val Loss: 0.3353\n",
      "Epoch [1/20], Train Loss: 0.2768, Val Loss: 0.2141\n",
      "Epoch [2/20], Batch [1/18], Train Loss: 0.3980\n",
      "Epoch [2/20], Batch [2/18], Train Loss: 0.5371\n",
      "Epoch [2/20], Batch [3/18], Train Loss: 0.4229\n",
      "Epoch [2/20], Batch [4/18], Train Loss: 0.5868\n",
      "Epoch [2/20], Batch [5/18], Train Loss: 0.4000\n",
      "Epoch [2/20], Batch [6/18], Train Loss: 0.4584\n",
      "Epoch [2/20], Batch [7/18], Train Loss: 0.4249\n",
      "Epoch [2/20], Batch [8/18], Train Loss: 0.4127\n",
      "Epoch [2/20], Batch [9/18], Train Loss: 0.3672\n",
      "Epoch [2/20], Batch [10/18], Train Loss: 0.4755\n",
      "Epoch [2/20], Batch [11/18], Train Loss: 0.7532\n",
      "Epoch [2/20], Batch [12/18], Train Loss: 0.4206\n",
      "Epoch [2/20], Batch [13/18], Train Loss: 0.4581\n",
      "Epoch [2/20], Batch [14/18], Train Loss: 0.3411\n",
      "Epoch [2/20], Batch [15/18], Train Loss: 0.4400\n",
      "Epoch [2/20], Batch [16/18], Train Loss: 0.4740\n",
      "Epoch [2/20], Batch [17/18], Train Loss: 0.5074\n",
      "Epoch [2/20], Batch [18/18], Train Loss: 0.4859\n",
      "Epoch [2/20], Validation Batch [1/5], Val Loss: 0.3273\n",
      "Epoch [2/20], Validation Batch [2/5], Val Loss: 0.3824\n",
      "Epoch [2/20], Validation Batch [3/5], Val Loss: 0.3970\n",
      "Epoch [2/20], Validation Batch [4/5], Val Loss: 0.3394\n",
      "Epoch [2/20], Validation Batch [5/5], Val Loss: 0.4280\n",
      "Epoch [2/20], Train Loss: 0.2323, Val Loss: 0.1874\n",
      "Epoch [3/20], Batch [1/18], Train Loss: 0.4751\n",
      "Epoch [3/20], Batch [2/18], Train Loss: 0.4326\n",
      "Epoch [3/20], Batch [3/18], Train Loss: 0.4423\n",
      "Epoch [3/20], Batch [4/18], Train Loss: 0.3842\n",
      "Epoch [3/20], Batch [5/18], Train Loss: 0.3227\n",
      "Epoch [3/20], Batch [6/18], Train Loss: 0.4028\n",
      "Epoch [3/20], Batch [7/18], Train Loss: 0.3669\n",
      "Epoch [3/20], Batch [8/18], Train Loss: 0.3750\n",
      "Epoch [3/20], Batch [9/18], Train Loss: 0.3238\n",
      "Epoch [3/20], Batch [10/18], Train Loss: 0.3305\n",
      "Epoch [3/20], Batch [11/18], Train Loss: 0.3248\n",
      "Epoch [3/20], Batch [12/18], Train Loss: 0.3516\n",
      "Epoch [3/20], Batch [13/18], Train Loss: 0.2919\n",
      "Epoch [3/20], Batch [14/18], Train Loss: 0.3760\n",
      "Epoch [3/20], Batch [15/18], Train Loss: 0.6014\n",
      "Epoch [3/20], Batch [16/18], Train Loss: 0.2662\n",
      "Epoch [3/20], Batch [17/18], Train Loss: 0.4007\n",
      "Epoch [3/20], Batch [18/18], Train Loss: 0.4520\n",
      "Epoch [3/20], Validation Batch [1/5], Val Loss: 0.3066\n",
      "Epoch [3/20], Validation Batch [2/5], Val Loss: 0.3591\n",
      "Epoch [3/20], Validation Batch [3/5], Val Loss: 0.3586\n",
      "Epoch [3/20], Validation Batch [4/5], Val Loss: 0.3266\n",
      "Epoch [3/20], Validation Batch [5/5], Val Loss: 0.4019\n",
      "Epoch [3/20], Train Loss: 0.1922, Val Loss: 0.1753\n",
      "Epoch [4/20], Batch [1/18], Train Loss: 0.3571\n",
      "Epoch [4/20], Batch [2/18], Train Loss: 0.4410\n",
      "Epoch [4/20], Batch [3/18], Train Loss: 0.3986\n",
      "Epoch [4/20], Batch [4/18], Train Loss: 0.4214\n",
      "Epoch [4/20], Batch [5/18], Train Loss: 0.3596\n",
      "Epoch [4/20], Batch [6/18], Train Loss: 0.3721\n",
      "Epoch [4/20], Batch [7/18], Train Loss: 0.4638\n",
      "Epoch [4/20], Batch [8/18], Train Loss: 0.3670\n",
      "Epoch [4/20], Batch [9/18], Train Loss: 0.6038\n",
      "Epoch [4/20], Batch [10/18], Train Loss: 0.4753\n",
      "Epoch [4/20], Batch [11/18], Train Loss: 0.3636\n",
      "Epoch [4/20], Batch [12/18], Train Loss: 0.4807\n",
      "Epoch [4/20], Batch [13/18], Train Loss: 0.4461\n",
      "Epoch [4/20], Batch [14/18], Train Loss: 0.4160\n",
      "Epoch [4/20], Batch [15/18], Train Loss: 0.4696\n",
      "Epoch [4/20], Batch [16/18], Train Loss: 0.4573\n",
      "Epoch [4/20], Batch [17/18], Train Loss: 0.4303\n",
      "Epoch [4/20], Batch [18/18], Train Loss: 0.4692\n",
      "Epoch [4/20], Validation Batch [1/5], Val Loss: 0.2802\n",
      "Epoch [4/20], Validation Batch [2/5], Val Loss: 0.3512\n",
      "Epoch [4/20], Validation Batch [3/5], Val Loss: 0.4110\n",
      "Epoch [4/20], Validation Batch [4/5], Val Loss: 0.3237\n",
      "Epoch [4/20], Validation Batch [5/5], Val Loss: 0.4736\n",
      "Epoch [4/20], Train Loss: 0.2165, Val Loss: 0.1840\n",
      "Epoch [5/20], Batch [1/18], Train Loss: 0.3553\n",
      "Epoch [5/20], Batch [2/18], Train Loss: 0.4088\n",
      "Epoch [5/20], Batch [3/18], Train Loss: 0.3864\n",
      "Epoch [5/20], Batch [4/18], Train Loss: 0.4994\n",
      "Epoch [5/20], Batch [5/18], Train Loss: 0.4355\n",
      "Epoch [5/20], Batch [6/18], Train Loss: 0.3393\n",
      "Epoch [5/20], Batch [7/18], Train Loss: 0.5574\n",
      "Epoch [5/20], Batch [8/18], Train Loss: 0.6723\n",
      "Epoch [5/20], Batch [9/18], Train Loss: 0.3350\n",
      "Epoch [5/20], Batch [10/18], Train Loss: 0.5500\n",
      "Epoch [5/20], Batch [11/18], Train Loss: 0.5485\n",
      "Epoch [5/20], Batch [12/18], Train Loss: 0.3692\n",
      "Epoch [5/20], Batch [13/18], Train Loss: 0.5361\n",
      "Epoch [5/20], Batch [14/18], Train Loss: 0.4372\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SeveritySimilarityDataset(annotation_file_path=config[\"annotation_data_path\"],\n",
    "                                    dataset_dir=config[\"image_folder_path\"],\n",
    "                                    phase=\"training\",\n",
    "                                    num_per_cluster=5,\n",
    "                                    input_size=(224, 224)\n",
    "                                    )\n",
    "\n",
    "test_dataset = SeveritySimilarityDataset(annotation_file_path=config[\"annotation_data_path\"],\n",
    "                                    dataset_dir=config[\"image_folder_path\"],\n",
    "                                    phase=\"test\",\n",
    "                                    num_per_cluster=5,\n",
    "                                    input_size=(224, 224)\n",
    "                                    )\n",
    "model = Setting_2_model(model_name=config[\"model_encoder\"],\n",
    "                        embed_dim=config[\"embedding_dim\"]\n",
    "                        )\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "\n",
    "from torch import optim as opt\n",
    "\n",
    "optimzer = opt.SGD(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "\n",
    "train_model(model=model, train_dataset=train_dataset,\n",
    "            val_dataset=test_dataset, num_epochs=config[\"num_epoch\"],\n",
    "            batch_size=config[\"batch_size\"], learning_rate=config[\"learning_rate\"],\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
