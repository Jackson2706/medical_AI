{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 2. Define utils of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_comparison(a, b):\n",
    "    \"\"\"\n",
    "    This function compares two values a and b.\n",
    "    If they are equal, it returns 1.\n",
    "    If they are not equal, it returns 0.\n",
    "    \"\"\"\n",
    "    if a == b:\n",
    "        # If a is equal to b, return 1\n",
    "        return 1\n",
    "    else:\n",
    "        # If a is not equal to b, return 0\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def gram_matrix(list_of_score):\n",
    "    \"\"\"\n",
    "    This function computes the Gram matrix for a list of scores.\n",
    "    \n",
    "    The Gram matrix is a matrix of pairwise comparisons of scores.\n",
    "    Each element [i][j] in the matrix represents the result of\n",
    "    comparing list_of_score[i] with list_of_score[j] using the\n",
    "    pair_comparison function.\n",
    "    \n",
    "    Args:\n",
    "    - list_of_score: A list of scores\n",
    "    \n",
    "    Returns:\n",
    "    - gram_matrix: The Gram matrix computed from the pairwise comparisons\n",
    "    \"\"\"\n",
    "    # Get the length of the list of scores\n",
    "    n = len(list_of_score)\n",
    "    \n",
    "    # Initialize the Gram matrix with zeros\n",
    "    gram_matrix = [[0 for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # Iterate through each pair of scores\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # Compute the pairwise comparison using the pair_comparison function\n",
    "            gram_matrix[i][j] = pair_comparison(list_of_score[i], list_of_score[j])\n",
    "    \n",
    "    # Return the computed Gram matrix\n",
    "    return gram_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       " [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       " [0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 1]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "list_of_score = [1,2,3,2,3,4,2,1,4]\n",
    "gram_matrix(list_of_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import cycle, islice\n",
    "\n",
    "def split_data_balanced_randomly(data, labels, num_groups, k):\n",
    "    \"\"\"\n",
    "    Split the data and labels randomly into a specified number of groups with balanced label distribution.\n",
    "    Each group will contain exactly k samples, with items possibly repeated to ensure balanced distribution.\n",
    "\n",
    "    Args:\n",
    "    - data: List of data elements\n",
    "    - labels: List of corresponding labels\n",
    "    - num_groups: Number of groups to split the data into\n",
    "    - k: Number of samples in each group\n",
    "\n",
    "    Returns:\n",
    "    - image_groups: List of groups containing data elements\n",
    "    - label_groups: List of groups containing corresponding labels\n",
    "    \"\"\"\n",
    "    # Ensure data and labels have the same length\n",
    "    assert len(data) == len(labels), \"Data and labels must have the same length.\"\n",
    "    \n",
    "    # Group data by labels\n",
    "    label_to_data = defaultdict(list)\n",
    "    for item, label in zip(data, labels):\n",
    "        label_to_data[label].append(item)\n",
    "    \n",
    "    # Prepare the result lists\n",
    "    image_groups = [[] for _ in range(num_groups)]\n",
    "    label_groups = [[] for _ in range(num_groups)]\n",
    "    \n",
    "    # Distribute the data into the groups with repeats allowed\n",
    "    for label, items in label_to_data.items():\n",
    "        random.shuffle(items)  # Shuffle items within each label group\n",
    "        item_cycle = iter(items)\n",
    "        for group_index in range(num_groups):\n",
    "            for _ in range(k // len(label_to_data)):\n",
    "                try:\n",
    "                    item = next(item_cycle)\n",
    "                except StopIteration:\n",
    "                    # If we run out of items for a label, shuffle and start again\n",
    "                    random.shuffle(items)\n",
    "                    item_cycle = iter(items)\n",
    "                    item = next(item_cycle)\n",
    "                image_groups[group_index].append(item)\n",
    "                label_groups[group_index].append(label)\n",
    "\n",
    "    return image_groups, label_groups\n",
    "\n",
    "def split_data_randomly(data, labels, num_groups, k):\n",
    "    \"\"\"\n",
    "    Split the data and labels randomly into a specified number of groups with each group containing exactly k samples.\n",
    "    Items can be repeated within and across groups to ensure balanced distribution.\n",
    "\n",
    "    Args:\n",
    "    - data: List of data elements\n",
    "    - labels: List of corresponding labels\n",
    "    - num_groups: Number of groups to split the data into\n",
    "    - k: Number of samples in each group\n",
    "\n",
    "    Returns:\n",
    "    - image_groups: List of groups containing data elements\n",
    "    - label_groups: List of groups containing corresponding labels\n",
    "    \"\"\"\n",
    "    # Ensure data and labels have the same length\n",
    "    assert len(data) == len(labels), \"Data and labels must have the same length.\"\n",
    "    \n",
    "    # Shuffle data and labels together\n",
    "    combined_data = list(zip(data, labels))\n",
    "    random.shuffle(combined_data)\n",
    "    \n",
    "    # Prepare the result lists\n",
    "    image_groups = [[] for _ in range(num_groups)]\n",
    "    label_groups = [[] for _ in range(num_groups)]\n",
    "    \n",
    "    # Fill each group with k samples, allowing repetition\n",
    "    for i in range(num_groups):\n",
    "        for j in range(k):\n",
    "            item = combined_data[random.randint(0, len(combined_data) - 1)]\n",
    "            image_groups[i].append(item[0])\n",
    "            label_groups[i].append(item[1])\n",
    "    \n",
    "    return image_groups, label_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "\n",
    "from torchvision import transforms\n",
    "from typing import Tuple\n",
    "class SeveritySimilarityDataset(Dataset):\n",
    "    def __init__(self, annotation_file_path: str, dataset_dir: str, phase: str = \"training\", num_per_cluster: int = 5, num_group: int = 10000, input_size: Tuple[int] = (224, 224)) -> None:\n",
    "        \"\"\"\n",
    "        Dataset class for severity similarity task.\n",
    "\n",
    "        Args:\n",
    "        - annotation_df: DataFrame containing annotations\n",
    "        - dataset_dir: Directory containing image data\n",
    "        - phase: Phase of the dataset (e.g., \"training\", \"validation\", \"testing\")\n",
    "        - num_per_cluster: Number of images per cluster\n",
    "        \"\"\"\n",
    "        super(SeveritySimilarityDataset, self).__init__()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        annotation_df = pd.read_csv(annotation_file_path)\n",
    "        # Filter data based on the specified phase\n",
    "        data = annotation_df[annotation_df[\"split\"] == phase]\n",
    "        # Concatenate study_id and image_id to get image paths\n",
    "        image_paths_df = data[\"study_id\"] + \"/\" + data[\"image_id\"] +\".png\"\n",
    "        image_paths = image_paths_df.tolist()\n",
    "    \n",
    "        # Get labels\n",
    "        labels_df = data[\"breast_birads\"]\n",
    "        labels = labels_df.to_list()\n",
    "\n",
    "        # Split data into clusters\n",
    "        if phase != \"test\":\n",
    "            self.image_cluster_list, self.label_cluster_list = split_data_balanced_randomly(image_paths, labels, num_group, num_per_cluster)\n",
    "        else:\n",
    "            self.image_cluster_list, self.label_cluster_list = split_data_randomly(image_paths, labels, num_group, num_per_cluster)\n",
    "\n",
    "\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of clusters in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.label_cluster_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Retrieves a cluster of images and its corresponding label cluster.\n",
    "\n",
    "        Args:\n",
    "        - index: Index of the cluster to retrieve\n",
    "\n",
    "        Returns:\n",
    "        - images: List of images in the cluster\n",
    "        - gram_matrix: Gram matrix computed from the label cluster\n",
    "        \"\"\"\n",
    "        image_cluster = self.image_cluster_list[index]\n",
    "        label_cluster = self.label_cluster_list[index]\n",
    "        images = []\n",
    "        for image_path in image_cluster:\n",
    "            abs_image_path = os.path.join(self.dataset_dir, image_path)\n",
    "            \n",
    "            # Read and preprocess image\n",
    "            image =  self._read_image(os.path.join(self.dataset_dir,image_path), self.input_size) # Transpose image tensor\n",
    "            images.append(image)\n",
    "        # # Compute Gram matrix\n",
    "        print(label_cluster)\n",
    "        gram_matrix_ = gram_matrix(label_cluster)\n",
    "        return  images, torch.tensor(gram_matrix_).to(torch.float)\n",
    "    \n",
    "    def _read_image(self, filepath, new_size):\n",
    "        image_pil = Image.open(filepath)\n",
    "        \n",
    "        # Kiểm tra chế độ của ảnh\n",
    "        if image_pil.mode != 'L':\n",
    "            image_pil = image_pil.convert('L')  # Chuyển đổi sang chế độ 'L' (grayscale) nếu cần thiết\n",
    "        \n",
    "        # Tạo ảnh RGB từ ảnh đơn kênh bằng cách sao chép giá trị của kênh đó vào cả ba kênh\n",
    "        image_pil = Image.merge('RGB', (image_pil, image_pil, image_pil))\n",
    "        \n",
    "        # Resize ảnh\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(new_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        resized_image = transform(image_pil)\n",
    "        resized_image = resized_image.to(torch.float)\n",
    "        \n",
    "        return resized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['BI-RADS 2', 'BI-RADS 2', 'BI-RADS 1', 'BI-RADS 1', 'BI-RADS 3', 'BI-RADS 3', 'BI-RADS 4', 'BI-RADS 4', 'BI-RADS 5', 'BI-RADS 5']\n",
      "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "data = SeveritySimilarityDataset(\"split_data.csv\", \"/media/jackson/Data/archive/Processed_Images\", \"training\", 10, 10000)\n",
    "print(len(data))\n",
    "print(data[3][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "\n",
    "class Setting_2_model(nn.Module):\n",
    "    def __init__(self, model_name: str, embed_dim: int):\n",
    "        \"\"\"\n",
    "        A custom model for Setting 2, which uses different pre-trained models\n",
    "        based on the specified `model_name`.\n",
    "\n",
    "        Args:\n",
    "        - model_name: Name of the pre-trained model to be used\n",
    "        - embed_dim: Dimension of the output embeddings\n",
    "        \"\"\"\n",
    "        super(Setting_2_model, self).__init__()\n",
    "\n",
    "        # Load the specified pre-trained model\n",
    "        if model_name.startswith('resnet'):\n",
    "            if model_name == 'resnet50':\n",
    "                self.model = models.resnet50(pretrained=True)\n",
    "            elif model_name == 'resnet101':\n",
    "                self.model = models.resnet101(pretrained=True)\n",
    "            elif model_name == 'resnet152':\n",
    "                self.model = models.resnet152(pretrained=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported ResNet model: {model_name}\")\n",
    "                \n",
    "            num_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        elif model_name.startswith('densenet'):\n",
    "            if model_name == 'densenet121':\n",
    "                self.model = models.densenet121(pretrained=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported DenseNet model: {model_name}\")\n",
    "                \n",
    "            num_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        elif model_name.startswith('vit'):\n",
    "            self.model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "            num_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "        - images: A list of input images\n",
    "\n",
    "        Returns:\n",
    "        - gram_matrix: The Gram matrix computed from the embeddings\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        # Iterate over the list of input images\n",
    "        for image in images:\n",
    "            # Pass the image through the pre-trained model\n",
    "            image_embedding = self.model(image)\n",
    "            # Append the embedding to the list\n",
    "            embeddings.append(image_embedding)\n",
    "        # Stack the embeddings along a new dimension\n",
    "        embeddings_tensor = torch.stack(embeddings, dim=1)\n",
    "        # Normalize the embeddings\n",
    "        embeddings_normalized = torch.nn.functional.normalize(embeddings_tensor, p=2, dim=2)\n",
    "\n",
    "        # Compute the Gram matrix\n",
    "        gram_matrix = torch.matmul(embeddings_normalized, embeddings_normalized.transpose(1, 2))\n",
    "        return gram_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        \"\"\"\n",
    "        Contrastive Loss function for computing the loss between predicted\n",
    "        and ground truth Gram matrices.\n",
    "\n",
    "        Args:\n",
    "        - margin: Margin value for the loss calculation\n",
    "        \"\"\"\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, gram_matrix_predicted, gram_matrix_ground_truth):\n",
    "        \"\"\"\n",
    "        Forward pass of the Contrastive Loss function.\n",
    "\n",
    "        Args:\n",
    "        - gram_matrix_predicted: Predicted Gram matrix\n",
    "        - gram_matrix_ground_truth: Ground truth Gram matrix\n",
    "\n",
    "        Returns:\n",
    "        - loss: Contrastive Learning Loss\n",
    "        \"\"\"\n",
    "        loss = gram_matrix_ground_truth * pow(gram_matrix_predicted, 2)\n",
    "        + (1-gram_matrix_ground_truth) * pow(torch.clamp(self.margin - gram_matrix_predicted, min=0.0), 2)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import torch\n",
    "\n",
    "gt = [1,2,3,2,3,4,2,1,4]\n",
    "gt = torch.tensor(gram_matrix(gt),dtype=torch.float)\n",
    "\n",
    "pred = [1,2,3,2,3,4,2,2,4]\n",
    "pred = torch.tensor(gram_matrix(pred), dtype=torch.float)\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "loss = criterion(pred, gt)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "def train_model(model, train_dataset, val_dataset, num_epochs=10, batch_size=32, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Train the model using the provided datasets.\n",
    "\n",
    "    Args:\n",
    "    - model: The model to be trained\n",
    "    - train_dataset: Dataset for training\n",
    "    - val_dataset: Dataset for validation\n",
    "    - num_epochs: Number of epochs for training\n",
    "    - batch_size: Batch size for training\n",
    "    - learning_rate: Learning rate for optimization\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained model\n",
    "    - train_losses: List of training losses\n",
    "    - val_losses: List of validation losses\n",
    "    \"\"\"\n",
    "    # Define data loaders for training and validation\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    # Lists to store training and validation losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    print(\"Training started...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader, 1):\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Compute average training loss for the epoch\n",
    "        epoch_train_loss = running_train_loss / len(train_dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(val_loader, 1):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Batch [{i}/{len(val_loader)}], Val Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        # Compute average validation loss for the epoch\n",
    "        epoch_val_loss = running_val_loss / len(val_dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "\n",
    "def test_model(model, test_dataset, batch_size=32):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "    - model: The trained model to be evaluated\n",
    "    - test_dataset: Dataset for testing\n",
    "    - batch_size: Batch size for testing\n",
    "\n",
    "    Returns:\n",
    "    - test_loss: Test loss\n",
    "    \"\"\"\n",
    "    # Define data loader for testing\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Define loss function\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables for computing test loss\n",
    "    running_test_loss = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    print(\"Testing started...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_test_loss += loss.item() * images.size(0)\n",
    "            num_samples += images.size(0)\n",
    "\n",
    "    # Compute test loss\n",
    "    test_loss = running_test_loss / num_samples\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(\"Testing completed.\")\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "# Example usage:\n",
    "# model = Setting_2_model(model_name='resnet50', embed_dim=512)\n",
    "# train_dataset = SeveritySimilarityDataset(train_annotation_df, dataset_dir, phase='training')\n",
    "# val_dataset = SeveritySimilarityDataset(val_annotation_df, dataset_dir, phase='validation')\n",
    "# test_dataset = SeveritySimilarityDataset(test_annotation_df, dataset_dir, phase='testing')\n",
    "# trained_model, train_losses, val_losses = train_model(model, train_dataset, val_dataset, num_epochs=10, batch_size=32, learning_rate=0.001)\n",
    "# test_loss = test_model(trained_model, test_dataset, batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"annotation_data_path\": \"split_data.csv\",\n",
    "    \"image_folder_path\": \"/media/jackson/Data/archive/Processed_Images\",\n",
    "    \"model_encoder\": \"resnet50\",\n",
    "    \"embedding_dim\": 512, \n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"num_epoch\": 5,\n",
    "    \"batch_size\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/envs/Paper/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/envs/Paper/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optim \u001b[38;5;28;01mas\u001b[39;00m opt\n\u001b[1;32m     22\u001b[0m optimzer \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     48\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/Paper/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Paper/lib/python3.8/site-packages/torch/autograd/__init__.py:259\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    250\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    251\u001b[0m     (inputs,)\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (torch\u001b[38;5;241m.\u001b[39mTensor, graph\u001b[38;5;241m.\u001b[39mGradientEdge))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[0;32m--> 259\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[0;32m~/anaconda3/envs/Paper/lib/python3.8/site-packages/torch/autograd/__init__.py:132\u001b[0m, in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         )\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_floating_point:\n\u001b[1;32m    136\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "train_dataset = SeveritySimilarityDataset(annotation_file_path=config[\"annotation_data_path\"],\n",
    "                                    dataset_dir=config[\"image_folder_path\"],\n",
    "                                    phase=\"training\",\n",
    "                                    num_per_cluster=5,\n",
    "                                    input_size=(224, 224)\n",
    "                                    )\n",
    "\n",
    "test_dataset = SeveritySimilarityDataset(annotation_file_path=config[\"annotation_data_path\"],\n",
    "                                    dataset_dir=config[\"image_folder_path\"],\n",
    "                                    phase=\"valid\",\n",
    "                                    num_per_cluster=5,\n",
    "                                    input_size=(224, 224)\n",
    "                                    )\n",
    "model = Setting_2_model(model_name=config[\"model_encoder\"],\n",
    "                        embed_dim=config[\"embedding_dim\"]\n",
    "                        )\n",
    "\n",
    "criterion = ContrastiveLoss()\n",
    "\n",
    "from torch import optim as opt\n",
    "\n",
    "optimzer = opt.SGD(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "\n",
    "train_model(model=model, train_dataset=train_dataset,\n",
    "            val_dataset=test_dataset, num_epochs=config[\"num_epoch\"],\n",
    "            batch_size=config[\"batch_size\"], learning_rate=config[\"learning_rate\"],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -7, -14],\n",
      "        [-47, -62]])\n",
      "tensor([[ -7, -14],\n",
      "        [-47, -62]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = 2 # [1,1,1,1]\n",
    "b = torch.tensor([[3,4], [7,8]])\n",
    "c = torch.tensor([[1,2], [5,6]])\n",
    "\n",
    "# print(b)\n",
    "# print(a-b)\n",
    "print(a - pow(b, 2))\n",
    "print(a -torch.pow(b, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
