{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"Label\": ['BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4', 'BI-RADS 5'],\n",
    "    \"extraction_feature_model_name\": \"resnet50\",\n",
    "    \"extraction_feature_model_path\": \"best.pt\",\n",
    "    \"embedding_dim\": 512,\n",
    "    \"annotation_file_path\": \"data.csv\",\n",
    "    \"dataset_dir\": \"data\",\n",
    "    \"phase\": \"training\",\n",
    "    \"input_size\": (224,224),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BI-RADS 2', 'BI-RADS 1', 'BI-RADS 3', 'BI-RADS 4', 'BI-RADS 5'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"breast-level_annotations.csv\")\n",
    "df[\"breast_birads\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class SeverityLevelDataset(Dataset):\n",
    "    def __init__(self, annotation_file_path: str, dataset_dir: str, phase: str = \"training\", input_size: Tuple = (224, 224), label_list: List = []):\n",
    "        super(SeverityLevelDataset, self).__init__()\n",
    "        self.dataset_dir = dataset_dir\n",
    "        annotation_df = pd.read_csv(annotation_file_path)\n",
    "        # Filter data based on the specified phase\n",
    "        data = annotation_df[annotation_df[\"split\"] == phase]\n",
    "        # Concatenate study_id and image_id to get image paths\n",
    "        image_paths_df = data[\"study_id\"] + \"/\" + data[\"image_id\"] +\".dicom\"\n",
    "        self.image_path_list = image_paths_df.tolist()\n",
    "    \n",
    "        # Get labels\n",
    "        labels_df = data[\"breast_birads\"]\n",
    "        self.label_name_list = labels_df.to_list()\n",
    "        self.input_size = input_size\n",
    "        self.label_id_list = label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_path_list[index]\n",
    "        image_tensor = self._read_resize_dicom(os.path.join(self.dataset_dir, image_path), self.input_size)\n",
    "\n",
    "        label_name = self.label_name_list[index]\n",
    "        label = self.label_id_list.index(label_name)\n",
    "        return image_tensor, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def _read_resize_dicom(self, filepath, new_size):\n",
    "         # Đọc file DICOM\n",
    "        dicom_data = pydicom.dcmread(filepath)\n",
    "        \n",
    "        # Chuyển đổi dữ liệu DICOM thành mảng numpy\n",
    "        image_array = dicom_data.pixel_array\n",
    "        \n",
    "        # Chuyển đổi mảng numpy thành ảnh PIL\n",
    "        image_pil = Image.fromarray(image_array)\n",
    "        \n",
    "        # Kiểm tra chế độ của ảnh\n",
    "        if image_pil.mode != 'L':\n",
    "            image_pil = image_pil.convert('L')  # Chuyển đổi sang chế độ 'L' (grayscale) nếu cần thiết\n",
    "        \n",
    "        # Tạo ảnh RGB từ ảnh đơn kênh bằng cách sao chép giá trị của kênh đó vào cả ba kênh\n",
    "        image_pil = Image.merge('RGB', (image_pil, image_pil, image_pil))\n",
    "        \n",
    "        # Resize ảnh\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(new_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        resized_image = transform(image_pil)\n",
    "        resized_image = resized_image.to(torch.float)\n",
    "        \n",
    "        return resized_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Extractionmodel(nn.Module):\n",
    "    def __init__(self, model_name: str, embed_dim: int):\n",
    "        \"\"\"\n",
    "        A custom model for Setting 2, which uses different pre-trained models\n",
    "        based on the specified `model_name`.\n",
    "\n",
    "        Args:\n",
    "        - model_name: Name of the pre-trained model to be used\n",
    "        - embed_dim: Dimension of the output embeddings\n",
    "        \"\"\"\n",
    "        super(Extractionmodel, self).__init__()\n",
    "\n",
    "        # Load the specified pre-trained model\n",
    "        if model_name.startswith('resnet'):\n",
    "            if model_name == 'resnet50':\n",
    "                self.model = models.resnet50(pretrained=True)\n",
    "            elif model_name == 'resnet101':\n",
    "                self.model = models.resnet101(pretrained=True)\n",
    "            elif model_name == 'resnet152':\n",
    "                self.model = models.resnet152(pretrained=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported ResNet model: {model_name}\")\n",
    "                \n",
    "            num_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        elif model_name.startswith('densenet'):\n",
    "            if model_name == 'densenet121':\n",
    "                self.model = models.densenet121(pretrained=True)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported DenseNet model: {model_name}\")\n",
    "                \n",
    "            num_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        elif model_name.startswith('vit'):\n",
    "            self.model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "            num_features = self.model.head.in_features\n",
    "            self.model.head = nn.Linear(num_features, embed_dim)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    def forward(self, image):\n",
    "        return self.model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class SeverityClassificationModel(nn.Module):\n",
    "    def __init__(self, feature_extraction_model, num_class):\n",
    "        super(SeverityClassificationModel, self).__init__()\n",
    "        self.feature_extractor = feature_extraction_model\n",
    "        self.fc = nn.Linear(512, num_class)\n",
    "\n",
    "    def forward(self, image):\n",
    "        feature = self.feature_extractor(image)\n",
    "        out = self.fc(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/envs/Paper/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/envs/Paper/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0180,  0.0904, -0.0035,  0.0287, -0.0462]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "checkpoint = torch.load(config[\"extraction_feature_model_path\"], map_location=torch.device(\"cpu\"))\n",
    "extractionmodel = Extractionmodel(model_name=config[\"extraction_feature_model_name\"], embed_dim=config[\"embedding_dim\"])\n",
    "extractionmodel.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "cls_model = SeverityClassificationModel(extractionmodel, 5)\n",
    "\n",
    "## dataset test\n",
    "datset = SeverityLevelDataset(annotation_file_path=config[\"annotation_file_path\"], \n",
    "                              dataset_dir=config[\"dataset_dir\"], \n",
    "                              phase=config[\"phase\"], \n",
    "                              input_size=config[\"input_size\"], \n",
    "                              label_list=config[\"Label\"]\n",
    "                              )\n",
    "\n",
    "sample_0 = datset[0]\n",
    "out = cls_model(sample_0[0].unsqueeze(0))\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
